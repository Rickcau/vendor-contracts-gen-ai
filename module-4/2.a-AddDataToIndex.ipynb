{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code is intended to be used with the index that is created in the 1b-CreateIndexV2 notebook.  \n",
    "\n",
    "First step is to load our environment variables from the .env file.  Print them out to make sure they look good."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.storage.blob import BlobServiceClient, generate_blob_sas, BlobSasPermissions\n",
    "from datetime import datetime, timedelta\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from pathlib import Path\n",
    "\n",
    "# Get root directory path\n",
    "root_dir = Path().absolute().parent\n",
    "env_path = root_dir / '.env'\n",
    "\n",
    "# Load .env from root\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "print(f\"Loaded .env from {env_path}\")\n",
    "# Access variables\n",
    "\n",
    "ai_search_endpoint = os.environ[\"AZURE_SEARCH_ENDPOINT\"]\n",
    "ai_search_key = os.environ[\"AZURE_SEARCH_KEY\"]\n",
    "ai_search_admin_key = os.environ[\"AZURE_SEARCH_ADMIN_KEY\"]\n",
    "ai_search_index = \"rdc-contracts-v1\"\n",
    "\n",
    "# Azure Document Intelligence settings\n",
    "endpoint = os.getenv('FORM_RECOGNIZER_ENDPOINT')\n",
    "key = os.getenv('FORM_RECOGNIZER_KEY')\n",
    "\n",
    "# Azure Storage settings\n",
    "storage_account_connection_string = os.getenv('STORAGE_ACCOUNT_CONNECTION_STRING')\n",
    "storage_account_name = os.getenv('STORAGE_ACCOUNT_NAME')\n",
    "storage_account_key = os.getenv('STORAGE_ACCOUNT_KEY')\n",
    "container_name = \"source\"\n",
    "\n",
    "# Azure OpenAI\n",
    "aoai_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "aoai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "aoai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "# Azure Document Intelligence settings\n",
    "form_recognizer_endpoint = os.getenv('FORM_RECOGNIZER_ENDPOINT')\n",
    "form_recognizer_key = os.getenv('FORM_RECOGNIZER_KEY')\n",
    "\n",
    "print(f\"storage_account_name: {  storage_account_name }\")\n",
    "print(f\"storage_account_connection_string: {  storage_account_connection_string[:4] + '*' * 30 + storage_account_connection_string[-4:] }\")\n",
    "print(f\"storage_acct_key: {  storage_account_key[:4] + '*' * 28 + storage_account_key[-4:] }\")\n",
    "print(f\"container_name: {container_name}\")\n",
    "print(f\"ai_search_endpoint: {ai_search_endpoint}\")\n",
    "print(f\"ai_search_key: {ai_search_key[:4] + '*' * 5 + ai_search_key[-4:]}\")\n",
    "print(f\"ai_search_index: {ai_search_index}\")\n",
    "print(f\"AOAI Deployment Name: {aoai_deployment}\")\n",
    "print(f\"AOAI EndPoint: {aoai_endpoint}\")\n",
    "print(f\"AOAI Key: {aoai_key[:4] + '*' * 5 + aoai_key[-4:]}\")\n",
    "print(f\"Form Recognizer EndPoint: {form_recognizer_endpoint }\")\n",
    "print(f\"Form Recognizer  Key: {form_recognizer_key[:4] + '*' * 5 + form_recognizer_key[-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TBD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.core.credentials import AzureKeyCredential\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from azure.ai.documentintelligence import DocumentIntelligenceClient\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from azure.storage.blob import generate_blob_sas\n",
    "from azure.storage.blob import BlobSasPermissions\n",
    "from azure.search.documents import SearchClient  \n",
    "from openai import AzureOpenAI \n",
    "from datetime import datetime, timedelta, UTC  # Added UTC\n",
    "import json\n",
    "import hashlib\n",
    "\n",
    "# Azure Document Intelligence settings\n",
    "endpoint = os.getenv('FORM_RECOGNIZER_ENDPOINT')\n",
    "key = os.getenv('FORM_RECOGNIZER_KEY')\n",
    "\n",
    "# Azure Storage settings\n",
    "storage_account_connection_string = os.getenv('STORAGE_ACCOUNT_CONNECTION_STRING')\n",
    "storage_account_name = os.getenv('STORAGE_ACCOUNT_NAME')\n",
    "storage_account_key = os.getenv('STORAGE_ACCOUNT_KEY')\n",
    "container_name = \"source\"\n",
    "\n",
    "# Azure OpenAI\n",
    "aoai_deployment = os.getenv(\"AZURE_OPENAI_DEPLOYMENT_NAME\")\n",
    "aoai_key = os.getenv(\"AZURE_OPENAI_API_KEY\")\n",
    "aoai_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\")\n",
    "\n",
    "aoai_client = AzureOpenAI(\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "        api_version=\"2023-05-15\"\n",
    "        )\n",
    "\n",
    "primary_llm = AzureChatOpenAI(\n",
    "    azure_deployment=aoai_deployment,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=aoai_key,\n",
    "    azure_endpoint=aoai_endpoint\n",
    ")\n",
    "\n",
    "primary_llm_json = AzureChatOpenAI(\n",
    "    azure_deployment=aoai_deployment,\n",
    "    api_version=\"2024-05-01-preview\",\n",
    "    temperature=0,\n",
    "    max_tokens=None,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    "    api_key=aoai_key,\n",
    "    azure_endpoint=aoai_endpoint,\n",
    "    model_kwargs={\"response_format\": {\"type\": \"json_object\"}}\n",
    ")\n",
    "\n",
    "search_client = SearchClient(ai_search_endpoint, ai_search_index, AzureKeyCredential(ai_search_admin_key))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we need to create a prompt to extract data from the document..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "contract_extraction_prompt = \"\"\"You are an AI assistant. Your job is to read the input contract, \n",
    "and output certain info in valid JSON format. Here is what you should be extracting:\n",
    "1. id - unique identifier for the document\n",
    "2. contractId - unique identifier for the contract\n",
    "3. vendorName - name of the vendor/supplier/contractor\n",
    "4. clientName - name of the client/customer\n",
    "5. contractTitle - title of the contract document\n",
    "6. effectiveDate - when the contract becomes effective\n",
    "7. endDate - when the contract expires\n",
    "8. signingDate - when the contract was signed\n",
    "9. status - current status of the contract (e.g., Active, Expired, Pending)\n",
    "10. compensation - monetary value of the contract\n",
    "11. terminationTerms - terms of termination\n",
    "12. paymentTerms - terms of payment\n",
    "13. currency - currency used in the contract\n",
    "14. parentContractId - ID of the parent contract (if this is an amendment)\n",
    "15. amendmentNumber - amendment number (if applicable)\n",
    "16. sourceFileName - name of the source file\n",
    "\n",
    "#Examples#\n",
    "User: MASTER SERVICES AGREEMENT\n",
    "This Master Services Agreement (the \"Agreement\") is made effective as of January 15, 2024 (the \"Effective Date\"), by and between:\n",
    "TechCorp Solutions Inc. (\"Vendor\")\n",
    "123 Tech Lane\n",
    "Silicon Valley, CA 94025\n",
    "and\n",
    "Global Enterprise Ltd. (\"Client\")\n",
    "456 Business Park\n",
    "New York, NY 10001\n",
    "Contract ID: MSA-2024-001\n",
    "1. SERVICES\n",
    "The Vendor agrees to provide software development services as outlined in Exhibit A.\n",
    "2. TERM\n",
    "This Agreement shall commence on the Effective Date and continue for a period of 24 months, ending on January 15, 2026.\n",
    "3. COMPENSATION\n",
    "Client agrees to pay Vendor a total of $250,000 USD for the services rendered.\n",
    "4. PAYMENT TERMS\n",
    "Payment shall be made in monthly installments of $10,416.67, due within 30 days of invoice date.\n",
    "Signed and executed on: January 10, 2024\n",
    "Status: Active\n",
    "File: MSA_TechCorp_Global_2024.pdf\n",
    "\n",
    "Assistant: {\n",
    "'id': 'DOC-20240115-001',\n",
    "'contractId': 'MSA-2024-001',\n",
    "'vendorName': 'TechCorp Solutions Inc.',\n",
    "'clientName': 'Global Enterprise Ltd.',\n",
    "'contractTitle': 'Master Services Agreement',\n",
    "'effectiveDate': '2024-01-15',\n",
    "'endDate': '2026-01-15',\n",
    "'signingDate': '2024-01-10',\n",
    "'status': 'Active',\n",
    "'compensation': 250000,\n",
    "'terminationTerms': 'This Agreement shall commence on the Effective Date and continue for a period of 24 months, ending on January 15, 2026',\n",
    "'paymentTerms': 'Payment shall be made in monthly installments of $10,416.67, due within 30 days of invoice date',\n",
    "'currency': 'USD',\n",
    "'parentContractId': null,\n",
    "'amendmentNumber': null,\n",
    "'sourceFileName': 'MSA_TechCorp_Global_2024.pdf'\n",
    "}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's create the functions needed to extract the fields as well as handle a few other important items.  In order to create indexes and update an index you need to be using the admim key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def llm_extraction(full_text):\n",
    "    \"\"\"\n",
    "    Extract contract information using the LLM model\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"system\", \"content\": contract_extraction_prompt}]\n",
    "    messages.append({\"role\": \"user\", \"content\": full_text})\n",
    "\n",
    "    response = primary_llm_json.invoke(messages)\n",
    "    extraction_json = json.loads(response.content)\n",
    "\n",
    "\n",
    "    return extraction_json\n",
    "\n",
    "def generate_sas_url(blob_name: str) -> str:\n",
    "    \"\"\"\n",
    "    Generate a full URL with SAS token for a specific blob\n",
    "    \"\"\"\n",
    "    # Define the permissions for the SAS token\n",
    "    sas_permissions = BlobSasPermissions(read=True)\n",
    "    \n",
    "    # Set token expiry time using timezone-aware datetime\n",
    "    expiry_time = datetime.now(UTC) + timedelta(hours=1)\n",
    "    \n",
    "    # Generate the SAS token\n",
    "    sas_token = generate_blob_sas(\n",
    "        account_name=storage_account_name,\n",
    "        account_key=storage_account_key,\n",
    "        container_name=container_name,\n",
    "        blob_name=blob_name,\n",
    "        permission=sas_permissions,\n",
    "        expiry=expiry_time\n",
    "    )\n",
    "    \n",
    "    # Construct the full URL including the SAS token\n",
    "    blob_url = f\"https://{storage_account_name}.blob.core.windows.net/{container_name}/{blob_name}?{sas_token}\"\n",
    "    \n",
    "    return blob_url\n",
    "\n",
    "def read_pdf(input_file: str) -> str:\n",
    "    \"\"\"\n",
    "    Read and analyze a PDF file using Azure Document Intelligence.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Get the URL with SAS token\n",
    "        document_url = generate_sas_url(input_file)\n",
    "        \n",
    "        print(f\"Starting document analysis...\")\n",
    "        \n",
    "        # Create Document Intelligence client\n",
    "        credential = AzureKeyCredential(form_recognizer_key)\n",
    "        doc_intelligence_client = DocumentIntelligenceClient(form_recognizer_endpoint, credential)\n",
    "\n",
    "        # Begin analysis with the authenticated URL using the correct model ID\n",
    "        poller = doc_intelligence_client.begin_analyze_document(\n",
    "            model_id=\"prebuilt-read\",  # Changed from \"prebuilt-document\" to \"prebuilt-read\"\n",
    "            analyze_request={\n",
    "                \"urlSource\": document_url\n",
    "            }\n",
    "        )\n",
    "\n",
    "        # Get results\n",
    "        result = poller.result()\n",
    "        \n",
    "        print(\"Successfully analyzed document\")\n",
    "        return result.content\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error analyzing document: {str(e)}\")\n",
    "        raise\n",
    "\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"): # model = \"deployment_name\"\n",
    "    \"\"\"Generate embeddings for the input text using the specified model.\"\"\"\n",
    "    return aoai_client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def generate_document_id(blob_name):\n",
    "    \"\"\"Generate a unique, deterministic ID for a document.\"\"\"\n",
    "    unique_string = f\"{blob_name}\"  # Use first 100 characters of content for uniqueness\n",
    "    return hashlib.md5(unique_string.encode()).hexdigest()\n",
    "\n",
    "def list_blobs_in_folder(container_client, folder_name):\n",
    "    return [blob for blob in container_client.list_blobs() if blob.name.startswith(folder_name)]\n",
    "\n",
    "def move_blob(source_container_client, destination_container_client, source_blob_name, destination_blob_name):\n",
    "    source_blob = source_container_client.get_blob_client(source_blob_name)\n",
    "    destination_blob = destination_container_client.get_blob_client(destination_blob_name)\n",
    "    \n",
    "    destination_blob.start_copy_from_url(source_blob.url)\n",
    "    source_blob.delete_blob()\n",
    "\n",
    "def populate_index():\n",
    "    print(\"Populating index...\")\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(storage_account_connection_string )\n",
    "    print(f\"Connection String: {storage_account_connection_string}\")\n",
    "    container_client = blob_service_client.get_container_client(container_name)\n",
    "    print(f\"Container Name: {container_name}\")\n",
    "    \n",
    "    blobs = list(container_client.list_blobs())\n",
    "    print(f\"Found {len(blobs)} blobs in the container\")\n",
    "    stage_blobs = blobs \n",
    "    count = 0 \n",
    "    for blob in stage_blobs:\n",
    "        count += 1\n",
    "        print(f\"\\n{count}. Processing {blob.name}\")\n",
    "        print(blob.name)\n",
    "        \n",
    "        try:\n",
    "            full_text = read_pdf(blob.name)\n",
    "            extraction_json = llm_extraction(full_text)\n",
    "\n",
    "            document_id = generate_document_id(blob.name)\n",
    "            contract_id = extraction_json[\"contractId\"]\n",
    "            vendor_name = extraction_json[\"vendorName\"]\n",
    "            client_name = extraction_json[\"clientName\"]\n",
    "            contract_title = extraction_json[\"contractTitle\"]\n",
    "            effective_date = extraction_json[\"effectiveDate\"]\n",
    "            end_date = extraction_json[\"endDate\"]\n",
    "            signing_date = extraction_json[\"signingDate\"]\n",
    "            status = extraction_json[\"status\"]\n",
    "            compensation = extraction_json[\"compensation\"]\n",
    "            termination_terms = extraction_json[\"terminationTerms\"]\n",
    "            parent_contract_id = extraction_json[\"parentContractId\"]\n",
    "            amendment_number = extraction_json[\"amendmentNumber\"]\n",
    "            creation_date = datetime.now()\n",
    "            content = full_text\n",
    "            vendorNameVector = generate_embeddings(extraction_json[\"vendorName\"])\n",
    "            # current_date = datetime.now(timezone.utc).isoformat()\n",
    "            source_file_name = os.path.basename(blob.name)\n",
    "            print(f\"Extracted contract ID: {contract_id}\")\n",
    "            print(f\"Extracted vendor name: {vendor_name}\")\n",
    "            print(f\"Extracted client name: {client_name}\")\n",
    "            print(f\"Extracted contract title: {contract_title}\")\n",
    "            print(f\"Extracted effective date: {effective_date}\")\n",
    "            print(f\"Extracted end date: {end_date}\")\n",
    "            print(f\"Extracted signing date: {signing_date}\")\n",
    "            print(f\"Status: {status}\")\n",
    "            print(f\"Extracted compensation: {compensation}\")\n",
    "            print(f\"Termination Terms: {termination_terms}\")\n",
    "            print(f\"Extracted parent contract ID: {parent_contract_id}\")\n",
    "            print(f\"Extracted amendment number: {amendment_number}\")\n",
    "            print(f\"Extracted creation date: {creation_date}\")\n",
    "            print(f\"Extracted source file name: {source_file_name}\")\n",
    "            \n",
    "            document = {\n",
    "                \"id\": document_id,\n",
    "                \"contractId\": contract_id ,\n",
    "                \"vendorName\": vendor_name,\n",
    "                \"clientName\": client_name,\n",
    "                \"contractTitle\": contract_title,\n",
    "                \"effectiveDate\": effective_date,\n",
    "                \"endDate\": end_date,\n",
    "                \"signingDate\": signing_date,\n",
    "                \"status\": status,\n",
    "                \"compensation\": compensation,\n",
    "                \"terminationTerms\": termination_terms,\n",
    "                \"parentContractId\": parent_contract_id,\n",
    "                \"amendmentNumber\": amendment_number,\n",
    "                \"creationDate\": creation_date,\n",
    "                \"sourceFileName\": source_file_name,\n",
    "                \"content\": content,\n",
    "                \"vendorNameVector\": vendorNameVector\n",
    "            }\n",
    "            \n",
    "            search_client.upload_documents(documents=[document])\n",
    "            \n",
    "            # Move the processed file to the 'processed' folder\n",
    "            destination_blob_name = blob.name.replace(\"source/\", \"processed/\")\n",
    "            # move_blob(container_client, container_client, blob.name, destination_blob_name)\n",
    "            \n",
    "            print(f\"Successfully processed {blob.name}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {blob.name}: {str(e)}\")\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        populate_index()\n",
    "        print(\"\\nPopulating Index has started...\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to populate the index: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vendor-contracts-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
