{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When to disregard results\n",
    "A semantic search will likely always return some results.  The questions is if those results are worthy of inclusion.  If you simply augment the prompt with any results that you return that leads token usage which could have been avoided.\n",
    "\n",
    "For example, if are using  highlight_fields=\"vendorName\" and a search is peformed for a vendor name and the @search.highlights indicates no direct text matches and there is a very low @search.score < 0.05 and @search.reranker_score < 3.0 then we can disregard the result as it's likely not going to be of use to the LLM.\n",
    "\n",
    "Take a look at the filter_search_results for an example and notice how the search for 'X' those results are disregarded even tho we get results in our search.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import index\n",
    "import os\n",
    "from pathlib import Path\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "from azure.search.documents import SearchClient\n",
    "from openai import AzureOpenAI  # If you're using Azure OpenAI for embeddings\n",
    "from dotenv import load_dotenv\n",
    "from azure.search.documents.models import VectorizedQuery\n",
    "\n",
    "\n",
    "# Get root directory path\n",
    "root_dir = Path().absolute().parent\n",
    "env_path = root_dir / '.env'\n",
    "\n",
    "# Load .env from root\n",
    "load_dotenv(dotenv_path=env_path)\n",
    "print(f\"Loaded .env from {env_path}\")\n",
    "# Access variables\n",
    "api_key = os.getenv('AZURE_OPENAI_API_KEY')\n",
    "debug = os.getenv('DEBUG')\n",
    "more_research = os.getenv('MORE_RESEARCH')\n",
    "index_name = os.getenv('AZURE_SEARCH_INDEX')\n",
    "\n",
    "\n",
    "print(f\"API Key: {  api_key[:4] + '*' * 28 + api_key[-4:] }\")\n",
    "print(f\"Index Name: {index_name}\")\n",
    "\n",
    "search_endpoint = os.getenv('AZURE_SEARCH_ENDPOINT')\n",
    "index_name = os.getenv('INDEX_NAME')\n",
    "search_key = os.getenv('AZURE_SEARCH_KEY')\n",
    "index_name = os.getenv('AZURE_SEARCH_INDEX')\n",
    "\n",
    "aoai_client = AzureOpenAI(\n",
    "        azure_endpoint = os.getenv(\"AZURE_OPENAI_ENDPOINT\"), \n",
    "        api_key=os.getenv(\"AZURE_OPENAI_KEY\"),  \n",
    "        api_version=\"2023-05-15\"\n",
    "        )\n",
    "\n",
    "def generate_embeddings(text, model=\"text-embedding-ada-002\"): # model = \"deployment_name\"\n",
    "    return aoai_client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "def filter_search_results(results):\n",
    "    filtered_results = []\n",
    "    for result in results:\n",
    "        base_score = result.get('@search.score', 0)\n",
    "        reranker_score = result.get('@search.reranker_score', 0)\n",
    "        highlights = result.get('@search.highlights')\n",
    "        \n",
    "        # For vendor name searches, require either:\n",
    "        # 1. Text highlights present (direct matches) OR\n",
    "        # 2. Higher minimum scores for non-highlighted results\n",
    "        if highlights:\n",
    "            # If we have highlights, use lower thresholds\n",
    "            if base_score >= 0.01 and reranker_score >= 1.0:\n",
    "                filtered_results.append(result)\n",
    "        else:\n",
    "            # No highlights - require higher scores to compensate\n",
    "            if base_score >= 0.05 and reranker_score >= 3.0:\n",
    "                filtered_results.append(result)\n",
    "    \n",
    "    return filtered_results if filtered_results else None\n",
    "\n",
    "# Test vector search\n",
    "search_client = SearchClient(endpoint=search_endpoint , index_name=index_name, credential=AzureKeyCredential(search_key))\n",
    "\n",
    "query = \"Fabrikam\"\n",
    "query_vector = generate_embeddings(query)\n",
    "\n",
    "top = 3\n",
    "vector_query = VectorizedQuery(vector=query_vector, k_nearest_neighbors=top, fields=\"vendorNameVector\", kind=\"vector\")\n",
    "print(f\"\\nFirst 1: using: {query}\")\n",
    "# results = search_client.search(\n",
    "#     search_text=query,  \n",
    "#     vector_queries=[vector_query],\n",
    "#     select=[\"id\", \"contractId\", \"vendorName\"]\n",
    "# )\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"id\", \"contractId\", \"vendorName\"],\n",
    "    highlight_fields=\"vendorName\",\n",
    "    query_type=\"semantic\",  # Enable semantic search\n",
    "    semantic_configuration_name=\"default\",  # You'll need to set this up\n",
    ")\n",
    "\n",
    "filtered_results=filter_search_results(results) # removed the items that are not good enough\n",
    "\n",
    "for result in filtered_results:\n",
    "    print(result)\n",
    "\n",
    "query = \"What can you tell me about the vendor agreement between Fabrikam Services and Contoso Elite?\"\n",
    "# Option 1: Pure Text Search with Weights\n",
    "print(f\"\\nPure Text Search with Weights, using: {query} \")\n",
    "results = search_client.search(\n",
    "    search_text= query,\n",
    "    select=[\"id\", \"contractId\", \"vendorName\"], \n",
    "    highlight_fields=\"vendorName\",\n",
    ")\n",
    "\n",
    "for result in results:\n",
    "    print(result)\n",
    "    \n",
    "# Option 2: Hybrid Search with Proper Query\n",
    "query = \"X\"\n",
    "print(f\"\\nHybrid Search with Proper Query, using: {query} \")\n",
    "\n",
    "query_vector = generate_embeddings(query)  \n",
    "\n",
    "vector_query = VectorizedQuery(vector=query_vector, k_nearest_neighbors=3, fields=\"vendorNameVector\", kind=\"vector\")\n",
    "\n",
    "results = search_client.search(\n",
    "    search_text=query,\n",
    "    vector_queries=[vector_query],\n",
    "    select=[\"id\", \"contractId\", \"vendorName\"],\n",
    "    highlight_fields=\"vendorName\",\n",
    "    query_type=\"semantic\",  # Enable semantic search\n",
    "    semantic_configuration_name=\"default\",  # You'll need to set this up\n",
    ")\n",
    "\n",
    "filtered_results=filter_search_results(results) # removed the items that are not good enough\n",
    "\n",
    "if filtered_results:  # if there are any results\n",
    "    for result in filtered_results:\n",
    "        print(result)\n",
    "else:\n",
    "    print(\"No results found\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vendor-contracts-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
